#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
TextProcessorç±»ç»¼åˆæµ‹è¯•æ¨¡å—

è¯¥æ¨¡å—æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨TextProcessorç±»è¿›è¡Œå®Œæ•´çš„PIIæ£€æµ‹å’ŒåŒ¿ååŒ–å¤„ç†ã€‚
åŒ…å«ä»¥ä¸‹æµ‹è¯•åœºæ™¯ï¼š
1. åŸºç¡€æ–‡æœ¬å¤„ç†
2. æ‰¹é‡æ–‡æœ¬å¤„ç† 
3. ä»…åˆ†ææ¨¡å¼
4. ä»…åŒ¿ååŒ–æ¨¡å¼
5. ä»…åˆ†å‰²æ¨¡å¼
6. è‡ªå®šä¹‰é…ç½®æµ‹è¯•
7. ä¸åŒè¯­è¨€æ”¯æŒæµ‹è¯•
8. æ€§èƒ½æµ‹è¯•

å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è¿è¡Œ:
python test/test_text_processor.py
æˆ–
PYTHONPATH=. python -m test.test_text_processor
"""

import os
import sys
import time
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
current_path = Path(__file__).resolve()
project_root = current_path.parent.parent
sys.path.insert(0, str(project_root))

from src.commons.loggers import get_module_logger, init_logging
from src.commons.utils import find_project_root
from src.configs import AppConfig
from src.configs.processors.text_processor import TextProcessorConfig
from src.processors.text_processor import (
    TextProcessor, ProcessingResult, 
    create_text_processor, get_text_processor,
    TextProcessorFactory
)

logger = get_module_logger(__name__)


class TextProcessorTester:
    """TextProcessoræµ‹è¯•ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.processor: Optional[TextProcessor] = None
        self.test_results: Dict[str, Any] = {}
        
        # æµ‹è¯•æ•°æ®
        self.test_texts = {
            "simple": "å¼ ä¸‰çš„æ‰‹æœºå·æ˜¯13912345678ã€‚",
            "complex": """
            å¼ ä¸‰æ˜¯ä¸€ä½è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œä»–çš„èº«ä»½è¯å·ç æ˜¯330102199901011234ï¼Œ
            ç”µè¯å·ç æ˜¯13800138000ï¼Œé‚®ç®±æ˜¯zhangsan@example.comã€‚
            ä»–çš„é“¶è¡Œå¡å·æ˜¯6222024000001234567ï¼Œè½¦ç‰Œå·æ˜¯æµ™A12345ã€‚
            ä»–ç»å¸¸è®¿é—®https://www.example.comç½‘ç«™è¿›è¡Œå­¦ä¹ ã€‚
            
            æå››ä¹Ÿæ˜¯ä¸€åå¼€å‘è€…ï¼Œèº«ä»½è¯å·441881199912123456ï¼Œ
            è”ç³»ç”µè¯15912345678ï¼Œå·¥ä½œåœ°å€åœ¨åŒ—äº¬å¸‚æœé˜³åŒºå»ºå›½é—¨å¤–å¤§è¡—1å·ã€‚
            """,
            "chinese_only": "ç‹äº”ä½åœ¨ä¸Šæµ·å¸‚æµ¦ä¸œæ–°åŒºé™†å®¶å˜´é‡‘èä¸­å¿ƒï¼Œèº«ä»½è¯æ˜¯310115198805156789ã€‚",
            "mixed": "Hello, æˆ‘æ˜¯John Smithï¼Œç”µè¯ï¼š+86-138-0013-8000ï¼Œé‚®ç®±ï¼šjohn@company.comã€‚",
            "empty": "",
            "no_pii": "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥ã€‚",
            "batch_test": [
                "ç¬¬ä¸€ä¸ªäººï¼šå¼ ä¸‰ï¼Œç”µè¯13812345678",
                "ç¬¬äºŒä¸ªäººï¼šæå››ï¼Œèº«ä»½è¯110101199001011234",
                "ç¬¬ä¸‰ä¸ªäººï¼šç‹äº”ï¼Œé‚®ç®±wangwu@example.com",
                "ç¬¬å››ä¸ªäººï¼šèµµå…­ï¼Œé“¶è¡Œå¡6222020000000000000"
            ]
        }
    
    def setup_processor(self, config: Optional[TextProcessorConfig] = None) -> None:
        """è®¾ç½®å¤„ç†å™¨"""
        try:
            if config:
                self.processor = TextProcessor(config)
            else:
                # ä½¿ç”¨é»˜è®¤é…ç½®æˆ–ä»é…ç½®æ–‡ä»¶åŠ è½½
                config_path = find_project_root(current_path) / "config" / "app_config.yaml"
                if config_path.exists():
                    app_config = AppConfig.load_from_yaml(str(config_path))
                    self.processor = TextProcessor(app_config.text_processor)
                else:
                    # ä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»º
                    self.processor = create_text_processor()
            
            logger.info("TextProcessor åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"TextProcessor åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def test_basic_processing(self) -> Dict[str, Any]:
        """æµ‹è¯•åŸºç¡€æ–‡æœ¬å¤„ç†åŠŸèƒ½"""
        logger.info("å¼€å§‹æµ‹è¯•åŸºç¡€æ–‡æœ¬å¤„ç†åŠŸèƒ½...")
        
        if not self.processor:
            return {
                "processing_successful": False,
                "error": "å¤„ç†å™¨æœªåˆå§‹åŒ–"
            }
        
        results = {}
        
        for name, text in self.test_texts.items():
            if name == "batch_test":
                continue  # è·³è¿‡æ‰¹é‡æµ‹è¯•æ•°æ®
            
            try:
                logger.info(f"å¤„ç†æµ‹è¯•æ–‡æœ¬: {name}")
                
                result = self.processor.process(
                    text=text,
                    enable_segmentation=True,
                    enable_analysis=True,
                    enable_anonymization=True,
                    language="zh"
                )
                
                # ç»Ÿè®¡ç»“æœ
                total_entities = sum(len(analysis) for analysis in result.analysis_results)
                
                results[name] = {
                    "original_length": len(text),
                    "segments_count": len(result.segments),
                    "entities_found": total_entities,
                    "anonymized_length": len(result.anonymized_text),
                    "processing_successful": True,
                    "anonymized_text": result.anonymized_text[:100] + "..." if len(result.anonymized_text) > 100 else result.anonymized_text
                }
                
                logger.info(f"  - åŸæ–‡é•¿åº¦: {len(text)}")
                logger.info(f"  - åˆ†æ®µæ•°é‡: {len(result.segments)}")
                logger.info(f"  - æ£€æµ‹åˆ°PIIå®ä½“æ•°: {total_entities}")
                logger.info(f"  - åŒ¿ååŒ–åæ–‡æœ¬é•¿åº¦: {len(result.anonymized_text)}")
                
                if total_entities > 0:
                    logger.info("  - æ£€æµ‹åˆ°çš„å®ä½“:")
                    for i, analysis_results in enumerate(result.analysis_results):
                        for entity in analysis_results:
                            logger.info(f"    æ®µè½{i+1}: {entity.entity_type} - '{entity.text}' (ç½®ä¿¡åº¦: {entity.score:.2f})")
                
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡æœ¬ '{name}' æ—¶å‡ºé”™: {e}")
                results[name] = {
                    "processing_successful": False,
                    "error": str(e)
                }
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æµ‹è¯•éƒ½æˆåŠŸ
        all_successful = all(result.get("processing_successful", False) for result in results.values())
        
        # æ·»åŠ æ€»ä½“æˆåŠŸæ ‡å¿—
        results["_overall_success"] = all_successful
        
        return results
    
    def test_batch_processing(self) -> Dict[str, Any]:
        """æµ‹è¯•æ‰¹é‡å¤„ç†åŠŸèƒ½"""
        logger.info("å¼€å§‹æµ‹è¯•æ‰¹é‡å¤„ç†åŠŸèƒ½...")
        
        batch_texts = self.test_texts["batch_test"]
        
        try:
            start_time = time.time()
            
            results = self.processor.batch_process(
                texts=batch_texts,
                enable_segmentation=True,
                enable_analysis=True,
                enable_anonymization=True,
                language="zh"
            )
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            # ç»Ÿè®¡æ‰¹é‡å¤„ç†ç»“æœ
            total_entities = 0
            successful_count = 0
            
            for i, result in enumerate(results):
                if not result.metadata.get('error'):
                    successful_count += 1
                    total_entities += sum(len(analysis) for analysis in result.analysis_results)
                    
                    logger.info(f"æ‰¹é‡å¤„ç† {i+1}: æ£€æµ‹åˆ° {sum(len(analysis) for analysis in result.analysis_results)} ä¸ªå®ä½“")
                    logger.info(f"  åŸæ–‡: {batch_texts[i]}")
                    logger.info(f"  åŒ¿ååŒ–: {result.anonymized_text}")
                else:
                    logger.error(f"æ‰¹é‡å¤„ç† {i+1} å¤±è´¥: {result.metadata.get('error')}")
            
            batch_result = {
                "total_texts": len(batch_texts),
                "successful_count": successful_count,
                "total_entities": total_entities,
                "processing_time": processing_time,
                "average_time_per_text": processing_time / len(batch_texts),
                "processing_successful": True
            }
            
            logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆ:")
            logger.info(f"  - æ€»æ–‡æœ¬æ•°: {len(batch_texts)}")
            logger.info(f"  - æˆåŠŸå¤„ç†: {successful_count}")
            logger.info(f"  - æ€»å®ä½“æ•°: {total_entities}")
            logger.info(f"  - æ€»è€—æ—¶: {processing_time:.2f}ç§’")
            logger.info(f"  - å¹³å‡è€—æ—¶: {processing_time / len(batch_texts):.2f}ç§’/æ–‡æœ¬")
            
            return batch_result
            
        except Exception as e:
            logger.error(f"æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            return {
                "processing_successful": False,
                "error": str(e)
            }
    
    def test_analysis_only(self) -> Dict[str, Any]:
        """æµ‹è¯•ä»…åˆ†æåŠŸèƒ½"""
        logger.info("å¼€å§‹æµ‹è¯•ä»…åˆ†æåŠŸèƒ½...")
        
        test_text = self.test_texts["complex"]
        
        try:
            analysis_results = self.processor.analyze_only(
                text=test_text,
                language="zh"
            )
            
            result = {
                "entities_found": len(analysis_results),
                "entities": [],
                "processing_successful": True
            }
            
            logger.info(f"ä»…åˆ†ææ¨¡å¼æ£€æµ‹åˆ° {len(analysis_results)} ä¸ªå®ä½“:")
            for entity in analysis_results:
                entity_info = {
                    "type": entity.entity_type,
                    "text": entity.text,
                    "score": entity.score,
                    "start": entity.start,
                    "end": entity.end
                }
                result["entities"].append(entity_info)
                logger.info(f"  - {entity.entity_type}: '{entity.text}' (ç½®ä¿¡åº¦: {entity.score:.2f}, ä½ç½®: {entity.start}-{entity.end})")
            
            return result
            
        except Exception as e:
            logger.error(f"ä»…åˆ†ææµ‹è¯•å¤±è´¥: {e}")
            return {
                "processing_successful": False,
                "error": str(e)
            }
    
    def test_anonymization_only(self) -> Dict[str, Any]:
        """æµ‹è¯•ä»…åŒ¿ååŒ–åŠŸèƒ½"""
        logger.info("å¼€å§‹æµ‹è¯•ä»…åŒ¿ååŒ–åŠŸèƒ½...")
        
        test_text = "å¼ ä¸‰çš„ç”µè¯æ˜¯13812345678ï¼Œé‚®ç®±æ˜¯zhangsan@example.com"
        
        try:
            # å…ˆè¿›è¡Œåˆ†æ
            analysis_results = self.processor.analyze_only(test_text, language="zh")
            
            # ç„¶åè¿›è¡ŒåŒ¿ååŒ–
            anonymization_result = self.processor.anonymize_only(
                text=test_text,
                analyzer_results=analysis_results
            )
            
            result = {
                "original_text": test_text,
                "anonymized_text": anonymization_result.text,
                "anonymization_items": len(anonymization_result.items),
                "processing_successful": True
            }
            
            logger.info(f"ä»…åŒ¿ååŒ–æµ‹è¯•:")
            logger.info(f"  åŸæ–‡: {test_text}")
            logger.info(f"  åŒ¿ååŒ–å: {anonymization_result.text}")
            logger.info(f"  åŒ¿ååŒ–é¡¹ç›®æ•°: {len(anonymization_result.items)}")
            
            return result
            
        except Exception as e:
            logger.error(f"ä»…åŒ¿ååŒ–æµ‹è¯•å¤±è´¥: {e}")
            return {
                "processing_successful": False,
                "error": str(e)
            }
    
    def test_segmentation_only(self) -> Dict[str, Any]:
        """æµ‹è¯•ä»…åˆ†å‰²åŠŸèƒ½"""
        logger.info("å¼€å§‹æµ‹è¯•ä»…åˆ†å‰²åŠŸèƒ½...")
        
        test_text = "è¿™æ˜¯ç¬¬ä¸€å¥è¯ã€‚è¿™æ˜¯ç¬¬äºŒå¥è¯ï¼è¿™æ˜¯ç¬¬ä¸‰å¥è¯ï¼Ÿè¿˜æœ‰ç¬¬å››å¥è¯ã€‚"
        
        try:
            segments = self.processor.segment_only(test_text)
            
            result = {
                "original_text": test_text,
                "segments_count": len(segments),
                "segments": [],
                "processing_successful": True
            }
            
            logger.info(f"ä»…åˆ†å‰²æµ‹è¯•:")
            logger.info(f"  åŸæ–‡: {test_text}")
            logger.info(f"  åˆ†å‰²ç»“æœ ({len(segments)} ä¸ªæ®µè½):")
            
            for i, segment in enumerate(segments):
                segment_info = {
                    "index": i + 1,
                    "text": segment.text,
                    "start": segment.start,
                    "end": segment.end
                }
                result["segments"].append(segment_info)
                logger.info(f"    æ®µè½{i+1}: '{segment.text}' (ä½ç½®: {segment.start}-{segment.end})")
            
            return result
            
        except Exception as e:
            logger.error(f"ä»…åˆ†å‰²æµ‹è¯•å¤±è´¥: {e}")
            return {
                "processing_successful": False,
                "error": str(e)
            }
    
    def test_custom_configuration(self) -> Dict[str, Any]:
        """æµ‹è¯•è‡ªå®šä¹‰é…ç½®"""
        logger.info("å¼€å§‹æµ‹è¯•è‡ªå®šä¹‰é…ç½®...")
        
        try:
            # åˆ›å»ºè‡ªå®šä¹‰é…ç½®
            from src.configs.processors.text_processor.core import AnalyzerConfig, AnonymizerConfig, CoreConfig
            
            custom_config = TextProcessorConfig()
            
            # è®¾ç½®è‡ªå®šä¹‰åŒ¿ååŒ–é…ç½®
            custom_config.core.anonymizer.entity_anonymization_config = {
                "PERSON": {
                    "operator": "replace",
                    "params": {"new_value": "[å§“å]"}
                },
                "PHONE_NUMBER": {
                    "operator": "mask", 
                    "params": {"masking_char": "*", "chars_to_mask": 8, "from_end": True}
                },
                "ID_CARD": {
                    "operator": "replace",
                    "params": {"new_value": "[èº«ä»½è¯]"}
                }
            }
            
            # åˆ›å»ºä½¿ç”¨è‡ªå®šä¹‰é…ç½®çš„å¤„ç†å™¨
            custom_processor = TextProcessor(custom_config)
            
            test_text = "å¼ ä¸‰çš„èº«ä»½è¯æ˜¯330102199901011234ï¼Œç”µè¯æ˜¯13812345678"
            
            result = custom_processor.process(
                text=test_text,
                enable_segmentation=True,
                enable_analysis=True,
                enable_anonymization=True,
                language="zh"
            )
            
            custom_result = {
                "original_text": test_text,
                "anonymized_text": result.anonymized_text,
                "entities_found": sum(len(analysis) for analysis in result.analysis_results),
                "processing_successful": True,
                "config_test": "custom_anonymization"
            }
            
            logger.info(f"è‡ªå®šä¹‰é…ç½®æµ‹è¯•:")
            logger.info(f"  åŸæ–‡: {test_text}")
            logger.info(f"  è‡ªå®šä¹‰åŒ¿ååŒ–å: {result.anonymized_text}")
            
            return custom_result
            
        except Exception as e:
            logger.error(f"è‡ªå®šä¹‰é…ç½®æµ‹è¯•å¤±è´¥: {e}")
            return {
                "processing_successful": False,
                "error": str(e)
            }
    
    def test_processor_features(self) -> Dict[str, Any]:
        """æµ‹è¯•å¤„ç†å™¨ç‰¹æ€§åŠŸèƒ½"""
        logger.info("å¼€å§‹æµ‹è¯•å¤„ç†å™¨ç‰¹æ€§åŠŸèƒ½...")
        
        try:
            # æµ‹è¯•æ”¯æŒçš„å®ä½“ç±»å‹
            supported_entities = self.processor.get_supported_entities()
            
            # æµ‹è¯•æ”¯æŒçš„æ“ä½œç¬¦
            supported_operators = self.processor.get_supported_operators()
            
            features_result = {
                "supported_entities_count": len(supported_entities),
                "supported_entities": supported_entities,
                "supported_operators_count": len(supported_operators),
                "supported_operators": supported_operators,
                "analyzer_available": self.processor.analyzer is not None,
                "anonymizer_available": self.processor.anonymizer is not None,
                "segmenter_available": self.processor.segmenter is not None,
                "processing_successful": True
            }
            
            logger.info(f"å¤„ç†å™¨ç‰¹æ€§:")
            logger.info(f"  æ”¯æŒçš„å®ä½“ç±»å‹ ({len(supported_entities)}ä¸ª): {supported_entities}")
            logger.info(f"  æ”¯æŒçš„æ“ä½œç¬¦ ({len(supported_operators)}ä¸ª): {supported_operators}")
            logger.info(f"  åˆ†æå™¨å¯ç”¨: {self.processor.analyzer is not None}")
            logger.info(f"  åŒ¿ååŒ–å™¨å¯ç”¨: {self.processor.anonymizer is not None}")
            logger.info(f"  åˆ†å‰²å™¨å¯ç”¨: {self.processor.segmenter is not None}")
            
            return features_result
            
        except Exception as e:
            logger.error(f"å¤„ç†å™¨ç‰¹æ€§æµ‹è¯•å¤±è´¥: {e}")
            return {
                "processing_successful": False,
                "error": str(e)
            }
    
    def test_performance(self) -> Dict[str, Any]:
        """æµ‹è¯•æ€§èƒ½"""
        logger.info("å¼€å§‹æµ‹è¯•æ€§èƒ½...")
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        large_text = self.test_texts["complex"] * 10  # é‡å¤10æ¬¡å¢åŠ æ–‡æœ¬é‡
        
        try:
            # æµ‹è¯•å•æ¬¡å¤„ç†æ€§èƒ½
            start_time = time.time()
            result = self.processor.process(
                text=large_text,
                enable_segmentation=True,
                enable_analysis=True,
                enable_anonymization=True,
                language="zh"
            )
            end_time = time.time()
            
            single_processing_time = end_time - start_time
            
            # æµ‹è¯•å¤šæ¬¡å¤„ç†æ€§èƒ½
            iterations = 5
            start_time = time.time()
            
            for i in range(iterations):
                self.processor.process(
                    text=self.test_texts["simple"],
                    enable_segmentation=True,
                    enable_analysis=True,
                    enable_anonymization=True,
                    language="zh"
                )
            
            end_time = time.time()
            multi_processing_time = end_time - start_time
            
            performance_result = {
                "large_text_length": len(large_text),
                "large_text_processing_time": single_processing_time,
                "large_text_entities_found": sum(len(analysis) for analysis in result.analysis_results),
                "multi_iterations": iterations,
                "multi_processing_time": multi_processing_time,
                "average_time_per_iteration": multi_processing_time / iterations,
                "processing_successful": True
            }
            
            logger.info(f"æ€§èƒ½æµ‹è¯•ç»“æœ:")
            logger.info(f"  å¤§æ–‡æœ¬é•¿åº¦: {len(large_text)} å­—ç¬¦")
            logger.info(f"  å¤§æ–‡æœ¬å¤„ç†æ—¶é—´: {single_processing_time:.2f}ç§’")
            logger.info(f"  å¤§æ–‡æœ¬æ£€æµ‹å®ä½“æ•°: {sum(len(analysis) for analysis in result.analysis_results)}")
            logger.info(f"  å¤šæ¬¡å¤„ç†({iterations}æ¬¡)æ€»æ—¶é—´: {multi_processing_time:.2f}ç§’")
            logger.info(f"  å¹³å‡æ¯æ¬¡å¤„ç†æ—¶é—´: {multi_processing_time / iterations:.2f}ç§’")
            
            return performance_result
            
        except Exception as e:
            logger.error(f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            return {
                "processing_successful": False,
                "error": str(e)
            }
    
    def run_all_tests(self) -> Dict[str, Any]:
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("=" * 80)
        logger.info("å¼€å§‹è¿è¡Œ TextProcessor ç»¼åˆæµ‹è¯•")
        logger.info("=" * 80)
        
        all_results = {}
        
        try:
            # è®¾ç½®å¤„ç†å™¨
            self.setup_processor()
            
            # è¿è¡Œå„é¡¹æµ‹è¯•
            test_functions = [
                ("basic_processing", self.test_basic_processing),
                ("batch_processing", self.test_batch_processing),
                ("analysis_only", self.test_analysis_only),
                ("anonymization_only", self.test_anonymization_only),
                ("segmentation_only", self.test_segmentation_only),
                ("custom_configuration", self.test_custom_configuration),
                ("processor_features", self.test_processor_features),
                ("performance", self.test_performance),
            ]
            
            for test_name, test_function in test_functions:
                logger.info(f"\n{'-' * 60}")
                logger.info(f"è¿è¡Œæµ‹è¯•: {test_name}")
                logger.info(f"{'-' * 60}")
                
                try:
                    result = test_function()
                    all_results[test_name] = result
                    
                    if result.get("processing_successful", False):
                        logger.info(f"âœ… æµ‹è¯• {test_name} é€šè¿‡")
                    else:
                        logger.error(f"âŒ æµ‹è¯• {test_name} å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
                except Exception as e:
                    logger.error(f"âŒ æµ‹è¯• {test_name} æ‰§è¡Œå¼‚å¸¸: {e}")
                    all_results[test_name] = {
                        "processing_successful": False,
                        "error": str(e)
                    }
            
            # æ±‡æ€»ç»“æœ
            successful_tests = sum(1 for result in all_results.values() if result.get("processing_successful", False))
            total_tests = len(all_results)
            
            logger.info(f"\n{'=' * 80}")
            logger.info(f"æµ‹è¯•å®Œæˆ - é€šè¿‡: {successful_tests}/{total_tests}")
            logger.info(f"{'=' * 80}")
            
            # è¯¦ç»†ç»“æœæ±‡æ€»
            all_results["summary"] = {
                "total_tests": total_tests,
                "successful_tests": successful_tests,
                "failed_tests": total_tests - successful_tests,
                "success_rate": successful_tests / total_tests if total_tests > 0 else 0
            }
            
            return all_results
            
        except Exception as e:
            logger.error(f"æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
            return {
                "processing_successful": False,
                "error": str(e)
            }


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–æ—¥å¿—
    import logging
    init_logging(level=logging.INFO)
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = TextProcessorTester()
    
    try:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        results = tester.run_all_tests()
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        summary = results.get("summary", {})
        if summary:
            print(f"\nğŸ¯ æœ€ç»ˆæµ‹è¯•ç»Ÿè®¡:")
            print(f"   æ€»æµ‹è¯•æ•°: {summary['total_tests']}")
            print(f"   æˆåŠŸæµ‹è¯•: {summary['successful_tests']}")
            print(f"   å¤±è´¥æµ‹è¯•: {summary['failed_tests']}")
            print(f"   æˆåŠŸç‡: {summary['success_rate']:.1%}")
            
            if summary['success_rate'] >= 0.8:
                print(f"ğŸ‰ TextProcessor å·¥ä½œæ­£å¸¸ï¼")
            else:
                print(f"âš ï¸  TextProcessor å¯èƒ½å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•ã€‚")
        
        return results
        
    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return None


if __name__ == "__main__":
    results = main()
    
    # å¦‚æœéœ€è¦ï¼Œå¯ä»¥å°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶
    if results:
        import json
        
        # ä¿å­˜æµ‹è¯•ç»“æœ
        results_file = project_root / "logs" / "text_processor_test_results.json"
        results_file.parent.mkdir(exist_ok=True)
        
        # åºåˆ—åŒ–ç»“æœï¼ˆå»é™¤ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡ï¼‰
        serializable_results = {}
        for key, value in results.items():
            if isinstance(value, dict):
                serializable_results[key] = value
            else:
                serializable_results[key] = str(value)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
