# éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†å¦‚ä½•åœ¨ä¸åŒç¯å¢ƒä¸­éƒ¨ç½² ALL PII IN ONE ç³»ç»Ÿã€‚

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒè¦æ±‚](#ç¯å¢ƒè¦æ±‚)
- [æœ¬åœ°éƒ¨ç½²](#æœ¬åœ°éƒ¨ç½²)
- [Dockeréƒ¨ç½²](#dockeréƒ¨ç½²)
- [äº‘ç«¯éƒ¨ç½²](#äº‘ç«¯éƒ¨ç½²)
- [ç”Ÿäº§ç¯å¢ƒé…ç½®](#ç”Ÿäº§ç¯å¢ƒé…ç½®)
- [ç›‘æ§å’Œæ—¥å¿—](#ç›‘æ§å’Œæ—¥å¿—)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## ğŸ”§ ç¯å¢ƒè¦æ±‚

### æœ€ä½é…ç½®

| ç»„ä»¶ | æœ€ä½è¦æ±‚ | æ¨èé…ç½® |
|------|----------|----------|
| CPU | 4æ ¸å¿ƒ | 8æ ¸å¿ƒ+ |
| å†…å­˜ | 8GB | 16GB+ |
| å­˜å‚¨ | 50GB | 100GB+ SSD |
| Python | 3.8+ | 3.10+ |
| CUDA | 11.8+ (å¯é€‰) | 12.0+ |

### æ“ä½œç³»ç»Ÿæ”¯æŒ

- âœ… Ubuntu 20.04+
- âœ… CentOS 8+
- âœ… macOS 12.0+
- âœ… Windows 10+
- âœ… Dockerå®¹å™¨

## ğŸ  æœ¬åœ°éƒ¨ç½²

### 1. å¿«é€Ÿå¯åŠ¨

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/your-username/all-pii-in-one.git
cd all-pii-in-one

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å¯åŠ¨åº”ç”¨
python src/app/main.py
```

### 2. å¼€å‘ç¯å¢ƒé…ç½®

```bash
# å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements-dev.txt

# å®‰è£…pre-commité’©å­
pre-commit install

# è¿è¡Œæµ‹è¯•
pytest test/

# ä»£ç æ ¼å¼åŒ–
black src/
isort src/
```

### 3. ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
# APIå¯†é’¥
HF_TOKEN=your_huggingface_token
GEMINI_API_KEY=your_gemini_api_key
OPENAI_API_KEY=your_openai_api_key

# åº”ç”¨é…ç½®
APP_ENV=development
LOG_LEVEL=DEBUG
TEMP_DIR=/tmp/pii_app

# è®¾å¤‡é…ç½®
DEVICE=cuda  # æˆ– cpu
GPU_ID=0

# UIé…ç½®
GRADIO_SERVER_NAME=0.0.0.0
GRADIO_SERVER_PORT=7860
GRADIO_SHARE=false
```

## ğŸ³ Dockeréƒ¨ç½²

### 1. åŸºç¡€Dockeréƒ¨ç½²

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    git \
    wget \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 7860

# å¯åŠ¨å‘½ä»¤
CMD ["python", "src/app/main.py"]
```

æ„å»ºå’Œè¿è¡Œï¼š

```bash
# æ„å»ºé•œåƒ
docker build -t all-pii-in-one .

# è¿è¡Œå®¹å™¨
docker run -p 7860:7860 \
  -e HF_TOKEN=your_token \
  -e GEMINI_API_KEY=your_key \
  -v $(pwd)/data:/app/data \
  all-pii-in-one
```

### 2. Docker Composeéƒ¨ç½²

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "7860:7860"
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - DEVICE=cpu
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./config:/app/config
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - app
    restart: unless-stopped

volumes:
  redis_data:
```

å¯åŠ¨æœåŠ¡ï¼š

```bash
docker-compose up -d
```

### 3. GPUæ”¯æŒçš„Dockeréƒ¨ç½²

```dockerfile
# Dockerfile.gpu
FROM nvidia/cuda:11.8-runtime-ubuntu20.04

# å®‰è£…Pythonå’Œç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    git \
    wget \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# è®¾ç½®Pythonåˆ«å
RUN ln -s /usr/bin/python3.10 /usr/bin/python

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements-gpu.txt .
RUN pip install --no-cache-dir -r requirements-gpu.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 7860

# å¯åŠ¨å‘½ä»¤
CMD ["python", "src/app/main.py"]
```

è¿è¡ŒGPUå®¹å™¨ï¼š

```bash
docker run --gpus all -p 7860:7860 \
  -e HF_TOKEN=your_token \
  -e GEMINI_API_KEY=your_key \
  -e DEVICE=cuda \
  all-pii-in-one:gpu
```

## â˜ï¸ äº‘ç«¯éƒ¨ç½²

### 1. AWSéƒ¨ç½²

#### EC2éƒ¨ç½²

```bash
# åˆ›å»ºEC2å®ä¾‹
aws ec2 run-instances \
  --image-id ami-0c02fb55956c7d316 \
  --instance-type g4dn.xlarge \
  --key-name your-key \
  --security-group-ids sg-xxxxxxxx \
  --subnet-id subnet-xxxxxxxx \
  --user-data file://user-data.sh

# user-data.sh è„šæœ¬
#!/bin/bash
yum update -y
yum install -y docker git
systemctl start docker
systemctl enable docker

# å®‰è£…Docker Compose
curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-linux-x86_64" -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose

# å…‹éš†é¡¹ç›®å¹¶å¯åŠ¨
git clone https://github.com/your-username/all-pii-in-one.git
cd all-pii-in-one
docker-compose up -d
```

#### ECSéƒ¨ç½²

```json
{
  "family": "all-pii-in-one",
  "taskRoleArn": "arn:aws:iam::account:role/ecsTaskRole",
  "executionRoleArn": "arn:aws:iam::account:role/ecsTaskExecutionRole",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "2048",
  "memory": "4096",
  "containerDefinitions": [
    {
      "name": "app",
      "image": "your-account.dkr.ecr.region.amazonaws.com/all-pii-in-one:latest",
      "portMappings": [
        {
          "containerPort": 7860,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "HF_TOKEN",
          "valueFrom": "arn:aws:secretsmanager:region:account:secret:hf-token"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/all-pii-in-one",
          "awslogs-region": "us-west-2",
          "awslogs-stream-prefix": "ecs"
        }
      }
    }
  ]
}
```

### 2. Google Cloud Platform

```yaml
# app.yaml for App Engine
runtime: python310

env_variables:
  HF_TOKEN: "your_token"
  GEMINI_API_KEY: "your_key"

resources:
  cpu: 2
  memory_gb: 4
  disk_size_gb: 20

automatic_scaling:
  min_instances: 1
  max_instances: 10
  target_cpu_utilization: 0.7
```

### 3. Azureéƒ¨ç½²

```yaml
# azure-container-instances.yml
apiVersion: 2019-12-01
location: eastus
name: all-pii-in-one
properties:
  containers:
  - name: app
    properties:
      image: your-registry.azurecr.io/all-pii-in-one:latest
      resources:
        requests:
          cpu: 2
          memoryInGb: 4
      ports:
      - port: 7860
      environmentVariables:
      - name: HF_TOKEN
        secureValue: your_token
  osType: Linux
  ipAddress:
    type: Public
    ports:
    - protocol: tcp
      port: 7860
  restartPolicy: Always
```

## ğŸ”§ ç”Ÿäº§ç¯å¢ƒé…ç½®

### 1. åå‘ä»£ç†é…ç½®

#### Nginxé…ç½®

```nginx
# nginx.conf
upstream app {
    server 127.0.0.1:7860;
}

server {
    listen 80;
    server_name your-domain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name your-domain.com;

    ssl_certificate /etc/ssl/certs/your-domain.crt;
    ssl_certificate_key /etc/ssl/private/your-domain.key;

    # SSLé…ç½®
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    ssl_prefer_server_ciphers off;

    # å®‰å…¨å¤´
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";

    # ä¸Šä¼ æ–‡ä»¶å¤§å°é™åˆ¶
    client_max_body_size 100M;

    location / {
        proxy_pass http://app;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocketæ”¯æŒ
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        
        # è¶…æ—¶è®¾ç½®
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }

    # é™æ€æ–‡ä»¶ç¼“å­˜
    location /static/ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

### 2. ç³»ç»ŸæœåŠ¡é…ç½®

```ini
# /etc/systemd/system/all-pii-in-one.service
[Unit]
Description=ALL PII IN ONE Service
After=network.target

[Service]
Type=simple
User=app
Group=app
WorkingDirectory=/opt/all-pii-in-one
Environment=PATH=/opt/all-pii-in-one/venv/bin
ExecStart=/opt/all-pii-in-one/venv/bin/python src/app/main.py
ExecReload=/bin/kill -HUP $MAINPID
Restart=always
RestartSec=10

# ç¯å¢ƒå˜é‡
Environment=HF_TOKEN=your_token
Environment=GEMINI_API_KEY=your_key
Environment=APP_ENV=production

# èµ„æºé™åˆ¶
LimitNOFILE=65536
LimitNPROC=4096

[Install]
WantedBy=multi-user.target
```

å¯ç”¨æœåŠ¡ï¼š

```bash
sudo systemctl daemon-reload
sudo systemctl enable all-pii-in-one
sudo systemctl start all-pii-in-one
sudo systemctl status all-pii-in-one
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### 1. æ—¥å¿—é…ç½®

```yaml
# logging.yaml
version: 1
disable_existing_loggers: false

formatters:
  standard:
    format: '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
  detailed:
    format: '%(asctime)s [%(levelname)s] %(name)s:%(lineno)d: %(message)s'

handlers:
  console:
    class: logging.StreamHandler
    level: INFO
    formatter: standard
    stream: ext://sys.stdout

  file:
    class: logging.handlers.RotatingFileHandler
    level: DEBUG
    formatter: detailed
    filename: logs/app.log
    maxBytes: 10485760  # 10MB
    backupCount: 5

  error_file:
    class: logging.handlers.RotatingFileHandler
    level: ERROR
    formatter: detailed
    filename: logs/error.log
    maxBytes: 10485760
    backupCount: 5

loggers:
  src:
    level: DEBUG
    handlers: [console, file]
    propagate: false

root:
  level: INFO
  handlers: [console, file, error_file]
```

### 2. å¥åº·æ£€æŸ¥

```python
# health_check.py
from flask import Flask, jsonify
import psutil
import torch

app = Flask(__name__)

@app.route('/health')
def health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    try:
        # æ£€æŸ¥CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        memory = psutil.virtual_memory()
        
        # æ£€æŸ¥GPUçŠ¶æ€ï¼ˆå¦‚æœæœ‰ï¼‰
        gpu_available = torch.cuda.is_available()
        gpu_memory = None
        if gpu_available:
            gpu_memory = torch.cuda.get_device_properties(0).total_memory
            
        status = {
            'status': 'healthy',
            'timestamp': datetime.utcnow().isoformat(),
            'system': {
                'cpu_percent': cpu_percent,
                'memory_percent': memory.percent,
                'disk_percent': psutil.disk_usage('/').percent
            },
            'gpu': {
                'available': gpu_available,
                'memory_total': gpu_memory
            }
        }
        
        # æ£€æŸ¥å…³é”®é˜ˆå€¼
        if cpu_percent > 90 or memory.percent > 90:
            status['status'] = 'warning'
            
        return jsonify(status), 200
        
    except Exception as e:
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

### 3. Prometheusç›‘æ§

```yaml
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'all-pii-in-one'
    static_configs:
      - targets: ['localhost:8080']
    metrics_path: '/metrics'
    scrape_interval: 30s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. åº”ç”¨å±‚ä¼˜åŒ–

```python
# é…ç½®ä¼˜åŒ–
production_config = {
    'general': {
        'device': 'cuda',
        'gpu_id': 0,
        'log_level': 'WARNING'
    },
    'processor': {
        'audio_processor': {
            'transcription': {
                'batch_size': 8,
                'compute_type': 'float16'
            }
        },
        'text_processor': {
            'analyzer': {
                'parallel_processing': True,
                'max_workers': 8,
                'enable_cache': True,
                'cache_size': 10000
            }
        }
    }
}
```

### 2. ç¼“å­˜ç­–ç•¥

```python
# Redisç¼“å­˜é…ç½®
CACHES = {
    'default': {
        'BACKEND': 'redis_cache.RedisCache',
        'LOCATION': 'redis://localhost:6379/1',
        'OPTIONS': {
            'CONNECTION_POOL_KWARGS': {
                'max_connections': 20,
                'retry_on_timeout': True,
            }
        },
        'TIMEOUT': 3600,  # 1å°æ—¶
        'KEY_PREFIX': 'pii_cache',
        'VERSION': 1,
    }
}
```

### 3. æ•°æ®åº“ä¼˜åŒ–

```python
# PostgreSQLé…ç½®
DATABASE_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'pii_db',
    'user': 'pii_user',
    'password': 'secure_password',
    'pool_size': 20,
    'max_overflow': 30,
    'pool_timeout': 30,
    'pool_recycle': 3600
}
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. å†…å­˜ä¸è¶³

```bash
# æ£€æŸ¥å†…å­˜ä½¿ç”¨
free -h
ps aux --sort=-%mem | head -10

# è§£å†³æ–¹æ¡ˆ
# 1. å‡å°‘batch_size
# 2. ä½¿ç”¨CPUè€ŒéGPU
# 3. å¢åŠ swapç©ºé—´
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

#### 2. GPUå†…å­˜ä¸è¶³

```python
# æ¸…ç†GPUå†…å­˜
import torch
torch.cuda.empty_cache()

# ç›‘æ§GPUä½¿ç”¨
nvidia-smi -l 1
```

#### 3. æ¨¡å‹ä¸‹è½½å¤±è´¥

```bash
# æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
export HF_HUB_CACHE=/path/to/cache
huggingface-cli download model_name --cache-dir /path/to/cache

# è®¾ç½®ä»£ç†
export HTTP_PROXY=http://proxy:port
export HTTPS_PROXY=https://proxy:port
```

#### 4. ç«¯å£å†²çª

```bash
# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tulpn | grep :7860
lsof -i :7860

# ä¿®æ”¹ç«¯å£
export GRADIO_SERVER_PORT=8080
```

### æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f logs/error.log

# æœç´¢ç‰¹å®šé”™è¯¯
grep -n "ERROR" logs/app.log | tail -20

# åˆ†ææ€§èƒ½
grep "processing time" logs/app.log | awk '{print $NF}' | sort -n
```

### æ€§èƒ½ç›‘æ§

```bash
# ç³»ç»Ÿèµ„æºç›‘æ§
htop
iostat -x 1
iotop

# åº”ç”¨æ€§èƒ½åˆ†æ
python -m cProfile -o profile.stats src/app/main.py
python -m pstats profile.stats
```

## ğŸ“‹ éƒ¨ç½²æ¸…å•

### éƒ¨ç½²å‰æ£€æŸ¥

- [ ] ç³»ç»Ÿèµ„æºå……è¶³
- [ ] ä¾èµ–åŒ…å·²å®‰è£…
- [ ] APIå¯†é’¥å·²é…ç½®
- [ ] é˜²ç«å¢™è§„åˆ™æ­£ç¡®
- [ ] SSLè¯ä¹¦æœ‰æ•ˆ
- [ ] æ•°æ®åº“è¿æ¥æ­£å¸¸
- [ ] ç¼“å­˜æœåŠ¡å¯ç”¨

### éƒ¨ç½²æ­¥éª¤

1. **ç¯å¢ƒå‡†å¤‡**
   - [ ] åˆ›å»ºç”¨æˆ·è´¦æˆ·
   - [ ] è®¾ç½®ç›®å½•æƒé™
   - [ ] é…ç½®ç¯å¢ƒå˜é‡

2. **åº”ç”¨éƒ¨ç½²**
   - [ ] ä»£ç éƒ¨ç½²
   - [ ] ä¾èµ–å®‰è£…
   - [ ] é…ç½®æ–‡ä»¶æ›´æ–°
   - [ ] æ•°æ®åº“è¿ç§»

3. **æœåŠ¡é…ç½®**
   - [ ] ç³»ç»ŸæœåŠ¡é…ç½®
   - [ ] åå‘ä»£ç†é…ç½®
   - [ ] ç›‘æ§é…ç½®
   - [ ] æ—¥å¿—è½®è½¬é…ç½®

4. **æµ‹è¯•éªŒè¯**
   - [ ] åŠŸèƒ½æµ‹è¯•
   - [ ] æ€§èƒ½æµ‹è¯•
   - [ ] å®‰å…¨æµ‹è¯•
   - [ ] ç›‘æ§éªŒè¯

5. **ä¸Šçº¿éƒ¨ç½²**
   - [ ] å¯åŠ¨æœåŠ¡
   - [ ] å¥åº·æ£€æŸ¥
   - [ ] æµé‡åˆ‡æ¢
   - [ ] ç›‘æ§å‘Šè­¦

---

å¦‚æœ‰éƒ¨ç½²é—®é¢˜ï¼Œè¯·å‚è€ƒ [æ•…éšœæ’é™¤æ–‡æ¡£](TROUBLESHOOTING.md) æˆ–æäº¤ [Issue](https://github.com/your-username/all-pii-in-one/issues)ã€‚
